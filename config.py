# -*- coding: utf-8 -*-
"""
MambaIRv2-GPPNN é…ç½®æ–‡ä»¶
åŸºäºMambaIRv2çš„æœ€ç»ˆç‰ˆæœ¬é…ç½®

å‚è€ƒå®˜æ–¹: https://github.com/csguoh/MambaIR?tab=readme-ov-file#installation
ç¡®ä¿ä½¿ç”¨MambaIRv2 Base/Largeè·å¾—æœ€ä¼˜æ€§èƒ½
"""

import argparse


class MambaIRv2_GPPNN_Config:
    """MambaIRv2-GPPNNé…ç½®ç±»"""
    
    # åŸºç¡€é…ç½® - ğŸ”¥ ä¼˜åŒ–34: æå‡è®­ç»ƒå‚æ•°
    BASE_CONFIG = {
        'model_size': 'base',
        'embed_dim': 96,
        'd_state': 16,
        'depths': [6, 6, 6, 6],
        'num_heads': [6, 6, 6, 6],
        'inner_rank': 32,
        'num_tokens': 128,
        'mlp_ratio': 2.0,
        'window_size': 8,

        # è®­ç»ƒå‚æ•° - ä¼˜åŒ–å
        'batch_size': 12,  # é€‚åº¦é™ä½batché¿å…æ˜¾å­˜å‹åŠ›
        'epochs': 80,      # å¢åŠ è®­ç»ƒè½®æ•°
        'learning_rate': 0.0002,  # æå‡åˆå§‹å­¦ä¹ ç‡
        'warmup_epochs': 5,       # ğŸ”¥ æ–°å¢: å­¦ä¹ ç‡warmup
        'min_lr': 1e-6,           # ğŸ”¥ æ–°å¢: æœ€å°å­¦ä¹ ç‡
        'weight_decay': 1e-4,
        'img_size': 512,

        # GPUè¦æ±‚
        'min_gpu_memory': '6GB',
        'recommended_gpu': 'RTX 3070',
        'max_batch_size': 8
    }
    
    # å¤§æ¨¡å‹é…ç½® - ğŸ”¥ ä¼˜åŒ–37: åŒæ­¥æ‰€æœ‰Baseä¼˜åŒ–åˆ°Large
    LARGE_CONFIG = {
        'model_size': 'large',
        'embed_dim': 128,
        'd_state': 20,
        'depths': [8, 8, 8, 8],
        'num_heads': [8, 8, 8, 8],
        'inner_rank': 48,
        'num_tokens': 256,
        'mlp_ratio': 2.0,
        'window_size': 8,

        # è®­ç»ƒå‚æ•° - ä¼˜åŒ–å
        'batch_size': 4,         # é€‚åº¦æå‡batch
        'epochs': 100,           # å¤§æ¨¡å‹éœ€è¦æ›´å¤šè½®æ¬¡
        'learning_rate': 0.0001, # æå‡å­¦ä¹ ç‡
        'warmup_epochs': 8,      # æ›´é•¿çš„warmup
        'min_lr': 5e-7,          # æœ€å°å­¦ä¹ ç‡
        'weight_decay': 1e-4,
        'img_size': 512,

        # GPUè¦æ±‚
        'min_gpu_memory': '12GB',
        'recommended_gpu': 'RTX 4080 / A100',
        'max_batch_size': 6
    }
    
    # æ•°æ®é…ç½®
    DATA_CONFIG = {
        'photo_root': './photo',
        'train_split': 'dataset',      # ä½¿ç”¨datasetç›®å½•ä½œä¸ºè®­ç»ƒé›†
        'test_split': 'testdateset',   # ä½¿ç”¨testdatesetç›®å½•ä½œä¸ºæµ‹è¯•é›†
        'train_ratio': 0.9,            # è®­ç»ƒé›†æ¯”ä¾‹
        'num_workers': 2,
        'pin_memory': True,
        
        # æ•°æ®å¢å¼º
        'horizontal_flip': True,
        'vertical_flip': True,
        'random_rotation': True,
        'color_jitter': False  # å…¨è‰²é”åŒ–é€šå¸¸ä¸éœ€è¦é¢œè‰²æŠ–åŠ¨
    }
    
    # æŸå¤±å‡½æ•°é…ç½® - ğŸ”¥ ä¼˜åŒ–35: å¢å¼ºæŸå¤±å‡½æ•°
    LOSS_CONFIG = {
        'alpha': 1.0,      # L1æŸå¤±æƒé‡
        'beta': 0.15,      # æ¢¯åº¦æŸå¤±æƒé‡ï¼ˆå¢å¼ºï¼‰
        'gamma': 0.05,     # ğŸ”¥ æ–°å¢: SSIMæŸå¤±æƒé‡
        'multi_scale': True,      # å¤šå°ºåº¦æŸå¤±
        'perceptual': False,      # æ„ŸçŸ¥æŸå¤±ï¼ˆå¯é€‰ï¼‰
        'edge_aware': True,       # ğŸ”¥ æ–°å¢: è¾¹ç¼˜æ„ŸçŸ¥æŸå¤±
        'frequency_loss': True    # ğŸ”¥ æ–°å¢: é¢‘åŸŸæŸå¤±
    }
    
    # ä¼˜åŒ–å™¨é…ç½® - ğŸ”¥ ä¼˜åŒ–36: ä½¿ç”¨Cosineé€€ç«
    OPTIMIZER_CONFIG = {
        'optimizer': 'AdamW',  # æ”¹ç”¨AdamWï¼Œæ›´å¥½çš„æ³›åŒ–
        'betas': (0.9, 0.999),
        'eps': 1e-8,
        'scheduler': 'CosineAnnealingWarmRestarts',  # Cosineé€€ç« + çƒ­é‡å¯
        'T_0': 20,        # ç¬¬ä¸€ä¸ªå‘¨æœŸé•¿åº¦
        'T_mult': 2,      # å‘¨æœŸå€å¢
        'eta_min': 1e-6,  # æœ€å°å­¦ä¹ ç‡
        'warmup_epochs': 5  # warmupè½®æ•°
    }
    
    # ğŸŒ ä¸–ç•Œæ¨¡å‹å¢å¼ºé…ç½® - åŸºäºã€Šæœ€æ–°ä»»åŠ¡è®¡åˆ’.mdã€‹
    WORLD_MODEL_CONFIG = {
        # ========== æ¨¡å—å¼€å…³ ==========
        'enable_world_model': False,     # æ€»å¼€å…³
        'use_wsm': False,                # ä¸–ç•ŒçŠ¶æ€è®°å¿† (World State Memory)
        'use_dca_fim': False,            # å¯å½¢å˜å¯¹é½ (Deformable Cross-Attention)
        'use_dsc': False,                # ç‰©ç†ä¸€è‡´æ€§æŸå¤± (Sensor Consistency)
        'use_wacx': False,               # é¢‘åŸŸä¸€è‡´æ€§æŸå¤± (Cross-band Consistency)
        'use_patch_prior': False,        # Patch Priorä¿®æ­£
        
        # ========== æŸå¤±æƒé‡ï¼ˆå‚è€ƒä»»åŠ¡è®¡åˆ’é»˜è®¤å€¼ï¼‰==========
        'lambda_s': 0.3,                 # DSCæƒé‡
        'lambda_g': 0.05,                # DCAå‡ ä½•æƒé‡
        'lambda_w': 0.5,                 # WAC-Xé¢‘åŸŸæƒé‡
        'lambda_p': 0.2,                 # Patchå…ˆéªŒæƒé‡
        
        # ========== WSMå‚æ•° ==========
        'wsm_hidden_dim': 128,           # GRUéšçŠ¶æ€ç»´åº¦
        'wsm_dropout': 0.1,              # Dropoutç‡
        'wsm_layer_scale_init': 0.1,    # LayerScaleåˆå§‹å€¼
        
        # ========== DCA-FIMå‚æ•° ==========
        'dca_num_points': 4,             # å½¢å˜é‡‡æ ·ç‚¹æ•°é‡
        'dca_offset_groups': 1,          # å½¢å˜åˆ†ç»„æ•°
        'dca_deform_weight': 0.3,        # å½¢å˜ç‰¹å¾èåˆæƒé‡
        
        # ========== DSCå‚æ•° ==========
        'dsc_mtf_kernel_size': 5,        # MTFå·ç§¯æ ¸å¤§å°
        'dsc_mtf_sigma': 1.0,            # é«˜æ–¯æ¨¡ç³Šsigma
        'dsc_spectral_response': [0.299, 0.587, 0.114],  # RGBâ†’PANå“åº”ç³»æ•°
        'dsc_lrms_weight': 0.3,          # LRMSæŸå¤±æƒé‡
        
        # ========== WAC-Xå‚æ•° ==========
        'wacx_interband_weight': 1.0,    # è·¨å¸¦ä¸€è‡´æ€§æƒé‡
        'wacx_pan_gate_weight': 0.5,     # PANé—¨æ§æƒé‡
        'wacx_freq_threshold': 0.1,      # é«˜é¢‘é˜ˆå€¼
        
        # ========== Patch Priorå‚æ•° ==========
        'patch_size': 32,                # Patchå°ºå¯¸
        'patch_overlap': 0.25,           # Patché‡å ç‡
        'patch_refiner_path': None,      # é¢„è®­ç»ƒç”Ÿæˆå™¨è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    }
    
    @classmethod
    def get_config(cls, model_size='base'):
        """è·å–æŒ‡å®šæ¨¡å‹å¤§å°çš„é…ç½®"""
        if model_size == 'base':
            config = cls.BASE_CONFIG.copy()
        elif model_size == 'large':
            config = cls.LARGE_CONFIG.copy()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹å¤§å°: {model_size}")
        
        # æ·»åŠ å…¶ä»–é…ç½®
        config.update(cls.DATA_CONFIG)
        config.update(cls.LOSS_CONFIG)
        config.update(cls.OPTIMIZER_CONFIG)
        
        return config
    
    @classmethod
    def print_config(cls, model_size='base'):
        """æ‰“å°é…ç½®ä¿¡æ¯"""
        config = cls.get_config(model_size)
        
        print(f"ğŸ”§ MambaIRv2-GPPNN {model_size.upper()} é…ç½®:")
        print(f"   æ¨¡å‹å‚æ•°:")
        print(f"     embed_dim: {config['embed_dim']}")
        print(f"     d_state: {config['d_state']}")
        print(f"     depths: {config['depths']}")
        print(f"     num_heads: {config['num_heads']}")
        
        print(f"   è®­ç»ƒå‚æ•°:")
        print(f"     batch_size: {config['batch_size']}")
        print(f"     epochs: {config['epochs']}")
        print(f"     learning_rate: {config['learning_rate']}")
        print(f"     img_size: {config['img_size']}x{config['img_size']}")
        
        print(f"   GPUè¦æ±‚:")
        print(f"     æœ€å°æ˜¾å­˜: {config['min_gpu_memory']}")
        print(f"     æ¨èGPU: {config['recommended_gpu']}")
        print(f"     æœ€å¤§batch_size: {config['max_batch_size']}")
        
        print(f"   æ•°æ®é…ç½®:")
        print(f"     photo_root: {config['photo_root']}")
        print(f"     num_workers: {config['num_workers']}")
        
        return config
    
    @classmethod
    def get_world_model_config(cls):
        """è·å–ä¸–ç•Œæ¨¡å‹é…ç½®"""
        return cls.WORLD_MODEL_CONFIG.copy()
    
    @classmethod
    def print_world_model_config(cls):
        """æ‰“å°ä¸–ç•Œæ¨¡å‹é…ç½®ä¿¡æ¯"""
        config = cls.get_world_model_config()
        
        if not config['enable_world_model']:
            print("ğŸŒ ä¸–ç•Œæ¨¡å‹å¢å¼º: æœªå¯ç”¨")
            return
        
        print("ğŸŒ ä¸–ç•Œæ¨¡å‹å¢å¼ºé…ç½®:")
        print(f"   æ¨¡å—çŠ¶æ€:")
        print(f"     WSM (ä¸–ç•ŒçŠ¶æ€è®°å¿†): {config['use_wsm']}")
        print(f"     DCA-FIM (å¯å½¢å˜å¯¹é½): {config['use_dca_fim']}")
        print(f"     DSC (ç‰©ç†ä¸€è‡´æ€§): {config['use_dsc']} (Î»s={config['lambda_s']})")
        print(f"     WAC-X (é¢‘åŸŸä¸€è‡´æ€§): {config['use_wacx']} (Î»w={config['lambda_w']})")
        print(f"     Patch Prior (æµå½¢ä¿®æ­£): {config['use_patch_prior']} (Î»p={config['lambda_p']})")
        
        if config['use_wsm']:
            print(f"   WSMå‚æ•°:")
            print(f"     hidden_dim={config['wsm_hidden_dim']}, dropout={config['wsm_dropout']}")
        
        if config['use_dca_fim']:
            print(f"   DCA-FIMå‚æ•°:")
            print(f"     num_points={config['dca_num_points']}, deform_weight={config['dca_deform_weight']}")
        
        return config


def create_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(description='MambaIRv2-GPPNN è®­ç»ƒ/æµ‹è¯•')
    
    # æ¨¡å‹é…ç½®
    parser.add_argument('--model_size', type=str, default='base', 
                       choices=['base', 'large'],
                       help='æ¨¡å‹å¤§å° (base/large)')
    
    # è®­ç»ƒé…ç½®
    parser.add_argument('--batch_size', type=int, default=None,
                       help='æ‰¹æ¬¡å¤§å°ï¼ˆè‡ªåŠ¨æ ¹æ®æ¨¡å‹å¤§å°è®¾ç½®ï¼‰')
    parser.add_argument('--epochs', type=int, default=None,
                       help='è®­ç»ƒè½®æ•°ï¼ˆè‡ªåŠ¨æ ¹æ®æ¨¡å‹å¤§å°è®¾ç½®ï¼‰')
    parser.add_argument('--lr', type=float, default=None,
                       help='å­¦ä¹ ç‡ï¼ˆè‡ªåŠ¨æ ¹æ®æ¨¡å‹å¤§å°è®¾ç½®ï¼‰')
    parser.add_argument('--img_size', type=int, default=256,
                       help='å›¾åƒå°ºå¯¸')
    
    # æ•°æ®é…ç½®
    parser.add_argument('--photo_root', type=str, default='../photo',
                       help='Photoç›®å½•è·¯å¾„')
    parser.add_argument('--num_workers', type=int, default=2,
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    
    # è¾“å‡ºé…ç½®
    parser.add_argument('--save_dir', type=str, default='./checkpoints',
                       help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--log_dir', type=str, default='./logs',
                       help='æ—¥å¿—ç›®å½•')
    parser.add_argument('--results_dir', type=str, default='./results',
                       help='ç»“æœç›®å½•')
    
    # è®¾å¤‡é…ç½®
    parser.add_argument('--device', type=str, default='auto',
                       help='è®¡ç®—è®¾å¤‡ (auto/cuda/cpu)')
    
    return parser


def update_args_with_config(args):
    """æ ¹æ®æ¨¡å‹å¤§å°æ›´æ–°å‚æ•°"""
    config = MambaIRv2_GPPNN_Config.get_config(args.model_size)
    
    # å¦‚æœå‚æ•°æ²¡æœ‰è®¾ç½®ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤å€¼
    if args.batch_size is None:
        args.batch_size = config['batch_size']
    if args.epochs is None:
        args.epochs = config['epochs']
    if args.lr is None:
        args.lr = config['learning_rate']
    
    return args


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    print("ğŸ§ª æµ‹è¯•MambaIRv2-GPPNNé…ç½®...")
    
    print("\n" + "="*50)
    MambaIRv2_GPPNN_Config.print_config('base')
    
    print("\n" + "="*50)
    MambaIRv2_GPPNN_Config.print_config('large')
    
    print("\nâœ… é…ç½®æµ‹è¯•å®Œæˆ!")
