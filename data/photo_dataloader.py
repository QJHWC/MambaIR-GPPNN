# -*- coding: utf-8 -*-
"""
Photoç›®å½•æ•°æ®åŠ è½½å™¨
é€‚é…ç”¨æˆ·çš„photoç›®å½•ç»“æ„ï¼š
- photo/dataset/ (650å¼ è®­ç»ƒå›¾åƒ)
- photo/testdateset/ (150å¼ æµ‹è¯•å›¾åƒ)

å‚è€ƒå®˜æ–¹Testingè§„èŒƒ: https://github.com/csguoh/MambaIR?tab=readme-ov-file#installation
"""

import os
import cv2
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import random
from PIL import Image


class PhotoDataset(Dataset):
    """
    Photoç›®å½•æ•°æ®é›†ç±»
    æ”¯æŒMS+PAN+GTä¸‰æ¨¡æ€æ•°æ®åŠ è½½
    """
    def __init__(self, 
                 photo_root,
                 mode='train',        # 'train', 'val', 'test'
                 data_split='dataset', # 'dataset' or 'testdateset'
                 transform=None,
                 img_size=None):
        """
        Args:
            photo_root: photoç›®å½•è·¯å¾„ (å¦‚: ./photo)
            mode: æ¨¡å¼ ('train', 'val', 'test')
            data_split: æ•°æ®åˆ†å‰² ('dataset'=è®­ç»ƒé›†, 'testdateset'=æµ‹è¯•é›†)
            transform: æ•°æ®å˜æ¢
            img_size: å›¾åƒå°ºå¯¸ï¼ŒNoneè¡¨ç¤ºä¿æŒåŸå°ºå¯¸
        """
        self.photo_root = photo_root
        self.mode = mode
        self.data_split = data_split
        self.transform = transform
        self.img_size = img_size
        
        # æ„å»ºæ•°æ®è·¯å¾„
        self.data_dir = os.path.join(photo_root, data_split)
        self.gt_dir = os.path.join(self.data_dir, 'GT')
        self.ms_dir = os.path.join(self.data_dir, 'MS')
        self.pan_dir = os.path.join(self.data_dir, 'PAN')
        
        # æ£€æŸ¥ç›®å½•å­˜åœ¨æ€§
        for dir_path in [self.gt_dir, self.ms_dir, self.pan_dir]:
            if not os.path.exists(dir_path):
                raise FileNotFoundError(f"Directory not found: {dir_path}")
        
        # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
        self.img_names = self._get_image_list()
        
        # æ•°æ®åˆ†å‰² (ä»…å¯¹datasetç›®å½•)
        if data_split == 'dataset':
            self.img_names = self._split_dataset()
        
        print(f"[Data] {self.__class__.__name__} initialized:")
        print(f"   Mode: {mode}")
        print(f"   Split: {data_split}")
        print(f"   Images: {len(self.img_names)}")
        print(f"   Directory: {self.data_dir}")
        
    def _get_image_list(self):
        """è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨"""
        gt_files = set(os.listdir(self.gt_dir))
        ms_files = set(os.listdir(self.ms_dir))
        pan_files = set(os.listdir(self.pan_dir))
        
        # æ‰¾åˆ°ä¸‰ä¸ªç›®å½•çš„äº¤é›†
        common_files = gt_files & ms_files & pan_files
        
        # æ’åºç¡®ä¿ä¸€è‡´æ€§
        img_names = sorted([f for f in common_files if f.lower().endswith(('.jpg', '.png', '.bmp'))])
        
        if len(img_names) == 0:
            raise ValueError(f"No common images found in {self.data_dir}")
            
        return img_names
    
    def _split_dataset(self):
        """åˆ†å‰²datasetç›®å½•ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"""
        # å‚è€ƒåŸGPPNNåˆ†å‰²ç­–ç•¥ï¼š600è®­ç»ƒ + 50éªŒè¯
        total_imgs = len(self.img_names)
        
        if self.mode == 'train':
            # å‰600å¼ ä½œä¸ºè®­ç»ƒé›†
            return self.img_names[:600] if total_imgs >= 600 else self.img_names[:int(0.9*total_imgs)]
        elif self.mode == 'val':
            # å50å¼ ä½œä¸ºéªŒè¯é›†
            return self.img_names[600:650] if total_imgs >= 650 else self.img_names[int(0.9*total_imgs):]
        else:
            # æµ‹è¯•æ¨¡å¼è¿”å›å…¨éƒ¨
            return self.img_names
    
    def __len__(self):
        return len(self.img_names)
    
    def __getitem__(self, idx):
        """è·å–å•ä¸ªæ ·æœ¬"""
        img_name = self.img_names[idx]
        
        # åŠ è½½å›¾åƒ
        gt_path = os.path.join(self.gt_dir, img_name)
        ms_path = os.path.join(self.ms_dir, img_name)
        pan_path = os.path.join(self.pan_dir, img_name)
        
        try:
            # ä½¿ç”¨OpenCVåŠ è½½å›¾åƒ (BGRæ ¼å¼)
            gt_img = cv2.imread(gt_path, cv2.IMREAD_COLOR)
            ms_img = cv2.imread(ms_path, cv2.IMREAD_COLOR)
            pan_img = cv2.imread(pan_path, cv2.IMREAD_GRAYSCALE)
            
            if gt_img is None or ms_img is None or pan_img is None:
                raise ValueError(f"Failed to load images for {img_name}")
            
            # è½¬æ¢ä¸ºRGBæ ¼å¼
            gt_img = cv2.cvtColor(gt_img, cv2.COLOR_BGR2RGB)
            ms_img = cv2.cvtColor(ms_img, cv2.COLOR_BGR2RGB)
            
            # ç¡®ä¿å°ºå¯¸ä¸€è‡´
            if self.img_size is not None:
                h, w = self.img_size
                gt_img = cv2.resize(gt_img, (w, h))
                ms_img = cv2.resize(ms_img, (w, h))
                pan_img = cv2.resize(pan_img, (w, h))
            
            # å½’ä¸€åŒ–åˆ°[0,1] (v2.2: æ·»åŠ æ˜¾å¼clipç¡®ä¿ä¸€è‡´æ€§)
            gt_img = np.clip(gt_img.astype(np.float32) / 255.0, 0.0, 1.0)
            ms_img = np.clip(ms_img.astype(np.float32) / 255.0, 0.0, 1.0)
            pan_img = np.clip(pan_img.astype(np.float32) / 255.0, 0.0, 1.0)

            # è½¬æ¢ä¸ºtorch tensor
            gt_tensor = torch.from_numpy(gt_img.transpose(2, 0, 1))  # [3, H, W]
            ms_tensor = torch.from_numpy(ms_img.transpose(2, 0, 1))  # [3, H, W]
            pan_tensor = torch.from_numpy(pan_img).unsqueeze(0)      # [1, H, W]
            
            # ğŸ”¥ v2.2: åº”ç”¨é…å¯¹å‡ ä½•å˜æ¢ (ç¿»è½¬+æ—‹è½¬)
            if self.mode == 'train':
                # å‡ ä½•å˜æ¢: ç¿»è½¬å’Œæ—‹è½¬ (è®­ç»ƒæ—¶åº”ç”¨)
                if random.random() < 0.5:  # æ°´å¹³ç¿»è½¬
                    gt_tensor = torch.flip(gt_tensor, dims=[2])
                    ms_tensor = torch.flip(ms_tensor, dims=[2])
                    pan_tensor = torch.flip(pan_tensor, dims=[2])

                if random.random() < 0.5:  # å‚ç›´ç¿»è½¬
                    gt_tensor = torch.flip(gt_tensor, dims=[1])
                    ms_tensor = torch.flip(ms_tensor, dims=[1])
                    pan_tensor = torch.flip(pan_tensor, dims=[1])

                if random.random() < 0.5:  # éšæœºæ—‹è½¬90Â°å€æ•°
                    k = random.choice([1, 2, 3])
                    gt_tensor = torch.rot90(gt_tensor, k, dims=[1, 2])
                    ms_tensor = torch.rot90(ms_tensor, k, dims=[1, 2])
                    pan_tensor = torch.rot90(pan_tensor, k, dims=[1, 2])

            # åº”ç”¨é¢œè‰²å˜æ¢ (ä»…GTå’ŒMSï¼Œä¸å¯¹PAN)
            if self.transform is not None and self.mode == 'train':
                gt_tensor = self.transform(gt_tensor)
                ms_tensor = self.transform(ms_tensor)

            return ms_tensor, pan_tensor, gt_tensor
            
        except Exception as e:
            print(f"âŒ Error loading {img_name}: {e}")
            # è¿”å›éšæœºæ•°æ®ä½œä¸ºfallback
            h, w = (256, 256) if self.img_size is None else self.img_size
            return (torch.randn(3, h, w), 
                    torch.randn(1, h, w), 
                    torch.randn(3, h, w))


class PairedRandomTransform:
    """
    ğŸ”¥ v2.2æ–°å¢: é…å¯¹æ•°æ®å¢å¼º - å¯¹MS/PAN/GTåŒæ­¥åº”ç”¨ç›¸åŒçš„å‡ ä½•å˜æ¢
    """
    def __init__(self, p=0.5):
        self.p = p

    def __call__(self, ms, pan, gt):
        # RandomHorizontalFlip
        if random.random() < self.p:
            ms = torch.flip(ms, dims=[2])
            pan = torch.flip(pan, dims=[2])
            gt = torch.flip(gt, dims=[2])

        # RandomVerticalFlip
        if random.random() < self.p:
            ms = torch.flip(ms, dims=[1])
            pan = torch.flip(pan, dims=[1])
            gt = torch.flip(gt, dims=[1])

        # Random90Â°Rotation
        if random.random() < self.p:
            k = random.choice([1, 2, 3])  # 90Â°, 180Â°, 270Â°
            ms = torch.rot90(ms, k, dims=[1, 2])
            pan = torch.rot90(pan, k, dims=[1, 2])
            gt = torch.rot90(gt, k, dims=[1, 2])

        return ms, pan, gt


def create_photo_dataloaders(photo_root='./photo',
                           batch_size=4,
                           num_workers=2,
                           img_size=None,
                           train_transform=None,
                           test_transform=None,
                           use_augmentation=True):
    """
    åˆ›å»ºphotoç›®å½•çš„æ•°æ®åŠ è½½å™¨ (v2.2ä¼˜åŒ–ç‰ˆ)

    Args:
        photo_root: photoç›®å½•è·¯å¾„
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        img_size: å›¾åƒå°ºå¯¸ (H, W) æˆ– None
        train_transform: è®­ç»ƒæ•°æ®å˜æ¢
        test_transform: æµ‹è¯•æ•°æ®å˜æ¢
        use_augmentation: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º (v2.2)

    Returns:
        train_loader, val_loader, test_loader
    """

    # ğŸ”¥ v2.2: å¢å¼ºçš„æ•°æ®å˜æ¢
    if train_transform is None and use_augmentation:
        train_transform = transforms.Compose([
            # è½»å¾®é¢œè‰²æŠ–åŠ¨ (é€‚ç”¨äºå…¨è‰²é”åŒ–ä»»åŠ¡)
            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05)
        ])
    elif train_transform is None:
        train_transform = transforms.Compose([])

    if test_transform is None:
        test_transform = transforms.Compose([])
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = PhotoDataset(
        photo_root=photo_root,
        mode='train',
        data_split='dataset',
        transform=train_transform,
        img_size=img_size
    )
    
    val_dataset = PhotoDataset(
        photo_root=photo_root,
        mode='val', 
        data_split='dataset',
        transform=test_transform,
        img_size=img_size
    )
    
    test_dataset = PhotoDataset(
        photo_root=photo_root,
        mode='test',
        data_split='testdateset',
        transform=test_transform,
        img_size=img_size
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    # ğŸ”§ å®‰å…¨çš„DataLoaderé…ç½® - é¿å…å¤šè¿›ç¨‹é—®é¢˜
    safe_pin_memory = True if num_workers == 0 else False  # å¤šè¿›ç¨‹æ—¶ç¦ç”¨pin_memory
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=safe_pin_memory,
        drop_last=True,
        persistent_workers=False,  # é¿å…è¿›ç¨‹æ³„æ¼
        prefetch_factor=2 if num_workers > 0 else None  # æ§åˆ¶é¢„å–
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=safe_pin_memory,
        drop_last=False,
        persistent_workers=False,
        prefetch_factor=2 if num_workers > 0 else None
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=safe_pin_memory,
        drop_last=False,
        persistent_workers=False,
        prefetch_factor=2 if num_workers > 0 else None
    )
    
    print(f"\n[Data] DataLoaders created:")
    print(f"   Train: {len(train_dataset)} samples, {len(train_loader)} batches")
    print(f"   Val: {len(val_dataset)} samples, {len(val_loader)} batches")
    print(f"   Test: {len(test_dataset)} samples, {len(test_loader)} batches")
    
    return train_loader, val_loader, test_loader


def test_photo_dataloader():
    """æµ‹è¯•photoæ•°æ®åŠ è½½å™¨"""
    print("ğŸ§ª æµ‹è¯•Photoæ•°æ®åŠ è½½å™¨...")
    
    try:
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = create_photo_dataloaders(
            photo_root='../photo',  # ç›¸å¯¹äºMambaIR-GPPNNç›®å½•
            batch_size=2,
            num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            img_size=(256, 256)
        )
        
        # æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½
        print("\nğŸ“¦ æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½:")
        for i, (ms, pan, gt) in enumerate(train_loader):
            print(f"   Batch {i}: MS{ms.shape}, PAN{pan.shape}, GT{gt.shape}")
            print(f"   æ•°æ®èŒƒå›´: MS[{ms.min():.3f}, {ms.max():.3f}], PAN[{pan.min():.3f}, {pan.max():.3f}]")
            if i >= 2:  # åªæµ‹è¯•å‰å‡ ä¸ªbatch
                break
        
        # æµ‹è¯•æµ‹è¯•æ•°æ®åŠ è½½
        print("\nğŸ“¦ æµ‹è¯•æµ‹è¯•æ•°æ®åŠ è½½:")
        for i, (ms, pan, gt) in enumerate(test_loader):
            print(f"   Batch {i}: MS{ms.shape}, PAN{pan.shape}, GT{gt.shape}")
            if i >= 1:
                break
        
        print("\nâœ… Photoæ•°æ®åŠ è½½å™¨æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"\nâŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_photo_dataloader()
