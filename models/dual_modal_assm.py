# -*- coding: utf-8 -*-
"""
åŒæ¨¡æ€æ³¨æ„åŠ›çŠ¶æ€ç©ºé—´æ¨¡å— (Dual Modal ASSM)
MambaIR-GPPNN çš„æ ¸å¿ƒç»„ä»¶
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math


def semantic_neighbor(x, index):
    """è¯­ä¹‰é‚»å±…å¯¹é½ - SGNé¢„å¤„ç†"""
    dim = index.dim()
    for _ in range(x.dim() - index.dim()):
        index = index.unsqueeze(-1)
    index = index.expand(x.shape)
    shuffled_x = torch.gather(x, dim=dim - 1, index=index)
    return shuffled_x


class DualModalSelectiveScan(nn.Module):
    """åŒæ¨¡æ€é€‰æ‹©æ€§æ‰«æ - å¼ºåŒ–ç‰ˆMambaç‰¹æ€§ with æ·±åº¦ç‰¹å¾èåˆ"""
    def __init__(self, d_model, d_state=16, dropout=0.1):
        super().__init__()
        self.d_model = d_model
        self.d_state = d_state

        # ğŸ”¥ ä¼˜åŒ–1: å¤šå±‚ç‰¹å¾æ˜ å°„ï¼Œå¢å¼ºéçº¿æ€§è¡¨è¾¾
        self.ms_linear = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.Linear(d_model, d_model)
        )
        self.pan_linear = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.Linear(d_model, d_model)
        )

        # ğŸ”¥ ä¼˜åŒ–2: åˆ†å±‚èåˆç­–ç•¥ - é€æ­¥æ·±åŒ–ç‰¹å¾äº¤äº’
        self.fusion_linear1 = nn.Linear(d_model * 2, d_model * 2)
        self.fusion_linear2 = nn.Linear(d_model * 2, d_model)
        self.fusion_gelu = nn.GELU()

        # çŠ¶æ€å½’ä¸€åŒ–ä¸é—¨æ§
        self.norm_ms = nn.LayerNorm(d_model)
        self.norm_pan = nn.LayerNorm(d_model)
        self.merge_norm = nn.LayerNorm(d_model)

        # ğŸ”¥ ä¼˜åŒ–3: åŒè·¯é—¨æ§ - åˆ†åˆ«æ§åˆ¶MSå’ŒPANçš„èåˆæ¯”ä¾‹
        self.ms_gate = nn.Linear(d_model * 2, d_model)
        self.pan_gate = nn.Linear(d_model * 2, d_model)
        self.context_gate = nn.Linear(d_model * 2, d_model)
        self.dropout = nn.Dropout(dropout)

        # ğŸ”¥ ä¼˜åŒ–4: å¢å¼ºæ®‹å·®é€šè·¯ - ä½¿ç”¨LayerScaleæŠ€æœ¯
        self.ms_residual = nn.Linear(d_model, d_model)
        self.pan_residual = nn.Linear(d_model, d_model)
        self.layer_scale_ms = nn.Parameter(torch.ones(d_model) * 0.1)
        self.layer_scale_pan = nn.Parameter(torch.ones(d_model) * 0.1)

    def forward(self, ms_seq, pan_seq, ms_prompt, pan_prompt):
        """åŒæ¨¡æ€ç‰¹å¾æ‰«æå¹¶èåˆ - ä¼˜åŒ–ç‰ˆ"""
        hidden_dim = ms_seq.shape[-1]
        prompt_dim = ms_prompt.shape[-1]

        # Promptå¯¹é½ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        if hidden_dim > prompt_dim:
            repeat_factor = hidden_dim // prompt_dim
            ms_prompt_proj = ms_prompt.repeat(1, 1, repeat_factor)
            pan_prompt_proj = pan_prompt.repeat(1, 1, repeat_factor)

            if hidden_dim % prompt_dim != 0:
                padding_size = hidden_dim - ms_prompt_proj.shape[-1]
                ms_padding = ms_prompt[:, :, :padding_size]
                pan_padding = pan_prompt[:, :, :padding_size]
                ms_prompt_proj = torch.cat([ms_prompt_proj, ms_padding], dim=-1)
                pan_prompt_proj = torch.cat([pan_prompt_proj, pan_padding], dim=-1)
        else:
            ms_prompt_proj = ms_prompt[:, :, :hidden_dim]
            pan_prompt_proj = pan_prompt[:, :, :hidden_dim]

        # ğŸ”¥ ä¼˜åŒ–5: å¢å¼ºçš„ç‰¹å¾æ˜ å°„ + Promptæ³¨å…¥
        ms_mapped = self.ms_linear(ms_seq)
        pan_mapped = self.pan_linear(pan_seq)
        ms_enhanced = self.norm_ms(ms_mapped + ms_prompt_proj)
        pan_enhanced = self.norm_pan(pan_mapped + pan_prompt_proj)

        # ğŸ”¥ ä¼˜åŒ–6: åˆ†å±‚æ·±åº¦èåˆ
        concat_feat = torch.cat([ms_enhanced, pan_enhanced], dim=-1)
        fusion_deep = self.fusion_gelu(self.fusion_linear1(concat_feat))
        fusion = self.fusion_linear2(fusion_deep)
        fusion = self.merge_norm(fusion)

        # ğŸ”¥ ä¼˜åŒ–7: åŒè·¯è‡ªé€‚åº”é—¨æ§
        gate_input = torch.cat([ms_seq, pan_seq], dim=-1)
        ms_gate_weight = torch.sigmoid(self.ms_gate(gate_input))
        pan_gate_weight = torch.sigmoid(self.pan_gate(gate_input))
        context_gate_weight = torch.sigmoid(self.context_gate(gate_input))

        # åº”ç”¨é—¨æ§ + Dropout
        fusion_gated = self.dropout(fusion * context_gate_weight)

        # ğŸ”¥ ä¼˜åŒ–8: å·®å¼‚åŒ–èåˆ - MSå’ŒPANä½¿ç”¨ä¸åŒçš„èåˆæ¯”ä¾‹
        ms_out = ms_enhanced + fusion_gated * ms_gate_weight * 0.6
        pan_out = pan_enhanced + fusion_gated * pan_gate_weight * 0.6

        # ğŸ”¥ ä¼˜åŒ–9: LayerScaleæ®‹å·® - å¯å­¦ä¹ çš„æ®‹å·®ç¼©æ”¾
        ms_out = ms_out + self.ms_residual(ms_seq) * self.layer_scale_ms
        pan_out = pan_out + self.pan_residual(pan_seq) * self.layer_scale_pan

        return ms_out, pan_out


class DualModal_ASSM(nn.Module):
    """
    åŒæ¨¡æ€æ³¨æ„åŠ›çŠ¶æ€ç©ºé—´æ¨¡å—

    æ ¸å¿ƒæµç¨‹:
    1. åˆ†åˆ«å¯¹ MS å’Œ PAN è¿›è¡ŒæŠ•å½±
    2. è‡ªé€‚åº”å±€éƒ¨ä¸Šä¸‹æ–‡å¢å¼º
    3. è¯­ä¹‰è·¯ç”± + prompt æ£€ç´¢
    4. åŒæ¨¡æ€é€‰æ‹©æ€§æ‰«æ
    5. æ¨¡æ€å¯¹é½è¾“å‡º
    """
    def __init__(self, dim, d_state=16, num_tokens=64, inner_rank=32, mlp_ratio=2.):
        super().__init__()
        self.dim = dim
        self.d_state = d_state
        self.num_tokens = num_tokens
        self.inner_rank = inner_rank

        self.expand = mlp_ratio
        hidden = int(self.dim * self.expand)

        # åŒæ¨¡æ€æŠ•å½±
        self.ms_proj = nn.Conv2d(self.dim, hidden, 1, 1, 0)
        self.pan_proj = nn.Conv2d(self.dim, hidden, 1, 1, 0)

        # ğŸ”¥ ä¼˜åŒ–10: å¤šå°ºåº¦å±€éƒ¨å¢å¼º - ä¸åŒæ„Ÿå—é‡æ•è·å¤šå±‚æ¬¡ç»†èŠ‚
        self.local_enhance_3x3 = nn.Conv2d(hidden, hidden, 3, 1, 1, groups=hidden)
        self.local_enhance_5x5 = nn.Conv2d(hidden, hidden, 5, 1, 2, groups=hidden)
        self.local_fusion = nn.Sequential(
            nn.Conv2d(hidden * 2, hidden, 1, 1, 0),
            nn.GELU(),
            nn.Conv2d(hidden, hidden, 1, 1, 0)
        )

        # ğŸ”¥ ä¼˜åŒ–11: é¢‘åŸŸå¢å¼º - æ•è·å…¨å±€é¢‘ç‡ä¿¡æ¯
        self.freq_enhance = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(hidden, hidden // 4, 1, 1, 0),
            nn.GELU(),
            nn.Conv2d(hidden // 4, hidden, 1, 1, 0),
            nn.Sigmoid()
        )

        self.modality_gate = nn.Conv2d(hidden * 2, hidden * 2, 1, 1, 0)
        self.CPE = nn.Conv2d(hidden, hidden, 3, 1, 1, groups=hidden)

        # è¯­ä¹‰è·¯ç”±
        self.route = nn.Sequential(
            nn.Linear(self.dim, self.dim // 3),
            nn.GELU(),
            nn.Linear(self.dim // 3, self.num_tokens),
            nn.LogSoftmax(dim=-1)
        )

        # Prompt åµŒå…¥
        self.ms_embedding = nn.Embedding(self.num_tokens, self.inner_rank)
        self.pan_embedding = nn.Embedding(self.num_tokens, self.inner_rank)
        self.token_proj = nn.Linear(self.inner_rank, self.d_state)

        # åŒæ¨¡æ€é€‰æ‹©æ€§æ‰«æ
        self.selective_scan = DualModalSelectiveScan(hidden, d_state)

        # è¾“å‡ºå±‚
        self.out_norm = nn.LayerNorm(hidden)
        self.out_proj = nn.Linear(hidden, dim)

        self._init_weights()

    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        nn.init.uniform_(self.ms_embedding.weight, -1/self.num_tokens, 1/self.num_tokens)
        nn.init.uniform_(self.pan_embedding.weight, -1/self.num_tokens, 1/self.num_tokens)

        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.trunc_normal_(m.weight, std=0.02)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.LayerNorm):
                nn.init.constant_(m.bias, 0)
                nn.init.constant_(m.weight, 1.0)

    def forward(self, ms_feat, pan_feat, x_size):
        """
        Args:
            ms_feat: [B, C, H, W]
            pan_feat: [B, C, H, W]
            x_size: (H, W)
        Returns:
            ms_enhanced, pan_enhanced: åŒæ¨¡æ€å¢å¼ºç‰¹å¾
        """
        B, C, H, W = ms_feat.shape

        ms_hidden = self.ms_proj(ms_feat)
        pan_hidden = self.pan_proj(pan_feat)

        # æ¡ä»¶ä½ç½®ç¼–ç ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        ms_hidden = ms_hidden * torch.sigmoid(self.CPE(ms_hidden))
        pan_hidden = pan_hidden * torch.sigmoid(self.CPE(pan_hidden))

        # ğŸ”¥ ä¼˜åŒ–12: å¤šå°ºåº¦å±€éƒ¨å¢å¼º
        ms_local_3x3 = self.local_enhance_3x3(ms_hidden)
        ms_local_5x5 = self.local_enhance_5x5(ms_hidden)
        ms_local = self.local_fusion(torch.cat([ms_local_3x3, ms_local_5x5], dim=1))

        pan_local_3x3 = self.local_enhance_3x3(pan_hidden)
        pan_local_5x5 = self.local_enhance_5x5(pan_hidden)
        pan_local = self.local_fusion(torch.cat([pan_local_3x3, pan_local_5x5], dim=1))

        # ğŸ”¥ ä¼˜åŒ–13: é¢‘åŸŸå…¨å±€å¢å¼º
        ms_freq = self.freq_enhance(ms_hidden)
        pan_freq = self.freq_enhance(pan_hidden)
        ms_hidden = ms_hidden * (1 + ms_freq)
        pan_hidden = pan_hidden * (1 + pan_freq)

        # ğŸ”¥ ä¼˜åŒ–14: è‡ªé€‚åº”æ¨¡æ€é—¨æ§
        gate_features = torch.sigmoid(self.modality_gate(torch.cat([ms_local, pan_local], dim=1)))
        gate_ms, gate_pan = torch.chunk(gate_features, 2, dim=1)
        ms_hidden = ms_hidden + ms_local * gate_ms * 0.7  # å¢å¼ºå±€éƒ¨å¢å¼ºçš„æ¯”ä¾‹
        pan_hidden = pan_hidden + pan_local * gate_pan * 0.7

        ms_seq = ms_hidden.flatten(2).transpose(1, 2)
        pan_seq = pan_hidden.flatten(2).transpose(1, 2)

        ms_seq_orig = ms_feat.flatten(2).transpose(1, 2)
        pan_seq_orig = pan_feat.flatten(2).transpose(1, 2)
        fused_for_route = (ms_seq_orig + pan_seq_orig) / 2
        route_logits = self.route(fused_for_route)
        route_policy = F.gumbel_softmax(route_logits, hard=True, dim=-1)

        ms_prompt = torch.matmul(route_policy, self.ms_embedding.weight)
        pan_prompt = torch.matmul(route_policy, self.pan_embedding.weight)

        ms_prompt = self.token_proj(ms_prompt)
        pan_prompt = self.token_proj(pan_prompt)

        semantic_indices = torch.argmax(route_policy, dim=-1)
        sorted_indices = torch.argsort(semantic_indices, dim=-1)
        reverse_indices = torch.argsort(sorted_indices, dim=-1)

        ms_semantic = torch.gather(ms_seq, 1, sorted_indices.unsqueeze(-1).expand(-1, -1, ms_seq.shape[-1]))
        pan_semantic = torch.gather(pan_seq, 1, sorted_indices.unsqueeze(-1).expand(-1, -1, pan_seq.shape[-1]))
        ms_prompt_sorted = torch.gather(ms_prompt, 1, sorted_indices.unsqueeze(-1).expand(-1, -1, ms_prompt.shape[-1]))
        pan_prompt_sorted = torch.gather(pan_prompt, 1, sorted_indices.unsqueeze(-1).expand(-1, -1, pan_prompt.shape[-1]))

        ms_out, pan_out = self.selective_scan(ms_semantic, pan_semantic, ms_prompt_sorted, pan_prompt_sorted)

        ms_out = torch.gather(ms_out, 1, reverse_indices.unsqueeze(-1).expand(-1, -1, ms_out.shape[-1]))
        pan_out = torch.gather(pan_out, 1, reverse_indices.unsqueeze(-1).expand(-1, -1, pan_out.shape[-1]))

        ms_final = self.out_proj(self.out_norm(ms_out))
        pan_final = self.out_proj(self.out_norm(pan_out))

        ms_final = ms_final.transpose(1, 2).reshape(B, C, H, W)
        pan_final = pan_final.transpose(1, 2).reshape(B, C, H, W)

        return ms_final, pan_final


if __name__ == "__main__":
    # æµ‹è¯•DualModal_ASSM
    print("ğŸš€ æµ‹è¯•DualModal_ASSMæ¨¡å—...")

    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    batch_size = 2
    channels = 64
    height, width = 64, 64

    ms_feat = torch.randn(batch_size, channels, height, width).to(device)
    pan_feat = torch.randn(batch_size, channels, height, width).to(device)

    assm = DualModal_ASSM(
        dim=channels,
        d_state=16,
        num_tokens=64,
        inner_rank=32
    ).to(device)

    with torch.no_grad():
        ms_out, pan_out = assm(ms_feat, pan_feat, x_size=(height, width))

    print(f"âœ… è¾“å…¥ - MS: {ms_feat.shape}, PAN: {pan_feat.shape}")
    print(f"âœ… è¾“å‡º - MS: {ms_out.shape}, PAN: {pan_out.shape}")
    print(f"âœ… å‚æ•°é‡: {sum(p.numel() for p in assm.parameters()):,}")

    print("ğŸ‰ DualModal_ASSMæµ‹è¯•é€šè¿‡!")
