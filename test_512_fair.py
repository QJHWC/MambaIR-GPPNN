# -*- coding: utf-8 -*-
"""
å…¬å¹³æµ‹è¯•è„šæœ¬ - 512å¯¹512
éªŒè¯MambaIRv2-GPPNNæ¶æ„åœ¨512Ã—512åˆ†è¾¨ç‡ä¸‹çš„çœŸå®æ€§èƒ½
"""

import os
import torch
import torch.nn.functional as F
import cv2
import numpy as np
from PIL import Image
import argparse
from tqdm import tqdm
import time

# æ·»åŠ æ¨¡å‹è·¯å¾„
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from models import create_mambairv2_gppnn


def calculate_psnr(img1, img2):
    """è®¡ç®—PSNR"""
    mse = torch.mean((img1 - img2) ** 2)
    if mse == 0:
        return float('inf')
    return 20 * torch.log10(1.0 / torch.sqrt(mse))


def calculate_ssim_simple(img1, img2):
    """ç®€åŒ–SSIMè®¡ç®—"""
    if isinstance(img1, torch.Tensor):
        img1 = img1.cpu().numpy()
    if isinstance(img2, torch.Tensor):
        img2 = img2.cpu().numpy()
    
    if len(img1.shape) == 4:
        img1 = img1[0]
        img2 = img2[0]
    
    # è½¬æ¢ä¸ºç°åº¦å›¾
    if img1.shape[0] == 3:
        img1 = np.mean(img1, axis=0)
        img2 = np.mean(img2, axis=0)
    
    mu1 = np.mean(img1)
    mu2 = np.mean(img2)
    sigma1 = np.var(img1)
    sigma2 = np.var(img2)
    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))
    
    c1 = 0.01 ** 2
    c2 = 0.03 ** 2
    
    ssim_val = ((2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)) / \
               ((mu1 ** 2 + mu2 ** 2 + c1) * (sigma1 + sigma2 + c2))
    
    return max(0, min(1, ssim_val))


def load_and_resize_image(img_path, target_size=(512, 512), is_grayscale=False):
    """åŠ è½½å¹¶resizeå›¾åƒåˆ°æŒ‡å®šå°ºå¯¸"""
    if is_grayscale:
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, target_size)
        img = img.astype(np.float32) / 255.0
        return torch.from_numpy(img).unsqueeze(0)  # [1, H, W]
    else:
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, target_size)
        img = img.astype(np.float32) / 255.0
        return torch.from_numpy(img.transpose(2, 0, 1))  # [3, H, W]


def test_fair_512(model_path, test_dir, output_dir, device):
    """å…¬å¹³çš„512Ã—512æµ‹è¯•"""
    
    print(f"ğŸ§ª å¼€å§‹å…¬å¹³æµ‹è¯• - 512Ã—512å¯¹512Ã—512")
    print("="*60)
    print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"   æµ‹è¯•ç›®å½•: {test_dir}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"   è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ—ï¸ åŠ è½½æ¨¡å‹...")
    checkpoint = torch.load(model_path, map_location=device)
    model_size = checkpoint.get('config', {}).get('model_size', 'base')
    print(f"   æ¨¡å‹å¤§å°: {model_size}")
    
    model = create_mambairv2_gppnn(model_size).to(device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"   æœ€ä½³PSNR: {checkpoint.get('best_psnr', 'æœªçŸ¥'):.2f}dB")
    print(f"   è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'æœªçŸ¥')}")
    
    # è·å–æµ‹è¯•å›¾åƒåˆ—è¡¨
    gt_dir = os.path.join(test_dir, 'GT')
    ms_dir = os.path.join(test_dir, 'MS') 
    pan_dir = os.path.join(test_dir, 'PAN')
    
    if not all(os.path.exists(d) for d in [gt_dir, ms_dir, pan_dir]):
        raise FileNotFoundError(f"æµ‹è¯•ç›®å½•ä¸å®Œæ•´: {test_dir}")
    
    img_names = [f for f in os.listdir(gt_dir) if f.lower().endswith(('.jpg', '.png'))]
    img_names = sorted(img_names)
    print(f"\nğŸ“Š æ‰¾åˆ°æµ‹è¯•å›¾åƒ: {len(img_names)}å¼ ")
    
    # æµ‹è¯•ç»Ÿè®¡
    total_psnr = 0.0
    total_ssim = 0.0
    valid_count = 0
    
    print(f"\nğŸ”¬ å¼€å§‹é€å¼ æµ‹è¯•...")
    start_time = time.time()
    
    with torch.no_grad():
        for i, img_name in enumerate(tqdm(img_names, desc="æµ‹è¯•è¿›åº¦")):
            try:
                # åŠ è½½åŸå§‹å›¾åƒå¹¶resizeåˆ°512Ã—512
                gt_path = os.path.join(gt_dir, img_name)
                ms_path = os.path.join(ms_dir, img_name)
                pan_path = os.path.join(pan_dir, img_name)
                
                # è¯»å–å¹¶resizeä¸º512Ã—512 (å…³é”®æ­¥éª¤!)
                gt_512 = load_and_resize_image(gt_path, (512, 512), False)
                ms_512 = load_and_resize_image(ms_path, (512, 512), False) 
                pan_512 = load_and_resize_image(pan_path, (512, 512), True)
                
                # æ·»åŠ batchç»´åº¦å¹¶ç§»åˆ°GPU
                gt_512 = gt_512.unsqueeze(0).to(device)    # [1, 3, 512, 512]
                ms_512 = ms_512.unsqueeze(0).to(device)    # [1, 3, 512, 512]
                pan_512 = pan_512.unsqueeze(0).to(device)  # [1, 1, 512, 512]
                
                # æ¨¡å‹æ¨ç†
                outputs = model(ms_512, pan_512)
                _, _, output_full = outputs
                
                # è®¡ç®—æŒ‡æ ‡ (512Ã—512 vs 512Ã—512 - å®Œå…¨å…¬å¹³!)
                psnr = calculate_psnr(output_full, gt_512)
                ssim = calculate_ssim_simple(output_full, gt_512)
                
                total_psnr += psnr.item()
                total_ssim += ssim
                valid_count += 1
                
                # ä¿å­˜ç»“æœå›¾åƒ (åªä¿å­˜å‰6å¼ )
                if i < 6:
                    # è½¬æ¢ä¸ºnumpyä¿å­˜
                    output_np = output_full[0].cpu().numpy().transpose(1, 2, 0)
                    output_np = np.clip(output_np * 255, 0, 255).astype(np.uint8)
                    output_pil = Image.fromarray(output_np)
                    
                    # ä¿å­˜ç»“æœ
                    result_name = f"result_{i:03d}_{img_name}"
                    output_pil.save(os.path.join(output_dir, result_name))
                    
                    # ä¹Ÿä¿å­˜GTå¯¹æ¯”
                    gt_np = gt_512[0].cpu().numpy().transpose(1, 2, 0)
                    gt_np = np.clip(gt_np * 255, 0, 255).astype(np.uint8)
                    gt_pil = Image.fromarray(gt_np)
                    gt_name = f"gt_{i:03d}_{img_name}"
                    gt_pil.save(os.path.join(output_dir, gt_name))
                
                # å®æ—¶æ˜¾ç¤ºè¿›åº¦
                if i % 20 == 0 and i > 0:
                    avg_psnr = total_psnr / valid_count
                    avg_ssim = total_ssim / valid_count
                    print(f"\n   ğŸ“Š ä¸­é—´ç»“æœ ({i}/{len(img_names)}å¼ ): PSNR={avg_psnr:.2f}dB, SSIM={avg_ssim:.4f}")
                    
            except Exception as e:
                print(f"\nâŒ å¤„ç†{img_name}æ—¶å‡ºé”™: {e}")
                continue
    
    # æœ€ç»ˆç»Ÿè®¡
    test_time = time.time() - start_time
    
    if valid_count > 0:
        avg_psnr = total_psnr / valid_count
        avg_ssim = total_ssim / valid_count
        
        print(f"\nğŸ‰ å…¬å¹³æµ‹è¯•å®Œæˆ!")
        print("="*60)
        print(f"ğŸ“Š æœ€ç»ˆç»“æœ (512Ã—512å¯¹512Ã—512):")
        print(f"   æµ‹è¯•å›¾åƒ: {valid_count}/{len(img_names)}å¼ ")
        print(f"   å¹³å‡PSNR: {avg_psnr:.2f}dB")
        print(f"   å¹³å‡SSIM: {avg_ssim:.4f}")
        print(f"   æµ‹è¯•è€—æ—¶: {test_time:.1f}ç§’")
        print(f"   å¹³å‡æ¯å¼ : {test_time/valid_count:.2f}ç§’")
        
        # æ€§èƒ½è¯„ä»·
        print(f"\nğŸ’¡ æ€§èƒ½è¯„ä»·:")
        if avg_psnr >= 32:
            print(f"   PSNR {avg_psnr:.2f}dB - ğŸŒŸ ä¼˜ç§€!")
        elif avg_psnr >= 30:
            print(f"   PSNR {avg_psnr:.2f}dB - âœ… è‰¯å¥½!")
        elif avg_psnr >= 27:
            print(f"   PSNR {avg_psnr:.2f}dB - âš ï¸  ä¸€èˆ¬")
        else:
            print(f"   PSNR {avg_psnr:.2f}dB - âŒ éœ€è¦æ”¹è¿›")
            
        if avg_ssim >= 0.95:
            print(f"   SSIM {avg_ssim:.4f} - ğŸŒŸ ä¼˜ç§€!")
        elif avg_ssim >= 0.90:
            print(f"   SSIM {avg_ssim:.4f} - âœ… è‰¯å¥½!")
        else:
            print(f"   SSIM {avg_ssim:.4f} - âš ï¸  éœ€è¦æ”¹è¿›")
        
        # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
        report = {
            'model_path': model_path,
            'test_images': valid_count,
            'avg_psnr': avg_psnr,
            'avg_ssim': avg_ssim,
            'test_time': test_time,
            'resolution': '512x512_fair_test'
        }
        
        import json
        with open(os.path.join(output_dir, 'test_report_512_fair.json'), 'w') as f:
            json.dump(report, f, indent=4)
        
        return avg_psnr, avg_ssim
    else:
        print("\nâŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å›¾åƒ!")
        return 0, 0


def main():
    parser = argparse.ArgumentParser(description='å…¬å¹³æµ‹è¯• - 512Ã—512å¯¹512Ã—512')
    parser.add_argument('--model_path', type=str, 
                       default='checkpoints/mambairv2_gppnn_latest/models/best_model.pth',
                       help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--test_dir', type=str, 
                       default='photo/testdateset',
                       help='æµ‹è¯•æ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', type=str,
                       default='test_results_512_fair',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default='auto',
                       help='è®¾å¤‡ (auto/cuda/cpu)')
    
    args = parser.parse_args()
    
    # è®¾å¤‡è®¾ç½®
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    # å¼€å§‹æµ‹è¯•
    test_fair_512(args.model_path, args.test_dir, args.output_dir, device)


if __name__ == '__main__':
    main()
